---
layout: post
title: Jedi Texts
---
![The sacred jedi texts](/img/sacredtexts.png)

# I think everyone should read these

## [The Sequences](https://wiki.lesswrong.com/wiki/Rationality:_From_AI_to_Zombies)
The most important thing about this book is its _preimage_, in other words, the books (including [ITILA](http://www.inference.org.uk/mackay/itila/), [Superforecasting](https://www.goodreads.com/book/show/23995360-superforecasting), and many others) and communities ([EA](https://en.wikipedia.org/wiki/Effective_altruism), [ratfic](https://www.reddit.com/r/HPMOR/comments/3f9gly/list_of_stories_similar_to_hpmor/), etc.) it leads you to.

# If you're grinding math/CS, these are important resources

## Rudiments
If you have to build up speed and patch up your background, nowhere is too basic to start. It's not too late. You're not that old yet. 
- [KhanAcademy](https://www.khanacademy.org/)
- [3blue1brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)
- [Schaum's outlines](https://www.amazon.com/s?k=schaums+outlines&ref=nb_sb_noss_2); order these for pennies plus $4 shipping. This is where you do piles of exercises to train up your habits.
- [How to Prove It](https://www.amazon.com/How-Prove-Structured-Daniel-Velleman/dp/0521446635); most books and lecturers use this word "proof" and pressure everyone into pretending they know what it means. If you're finding a frank discussion of what a proof is (and more importantly, what a proof is not) to be frustratingly rare, this book will be valuable.  
- [brilliant.org daily problems](https://brilliant.org/daily-problems/)

## [Build Your Own Lisp in C](http://buildyourownlisp.com/)
This book leveled me up a lot. If you're beginner to intermediate at software and you're looking new avenues, I hope you complete it. 

## [Programming in Haskell](http://www.cs.nott.ac.uk/~pszgmh/pih.html)

## [OPLSS (youtube)](https://www.youtube.com/channel/UCDe6N9R7U-RYWA57wzJQ2SQ)
There's a lot more OPLSS content uploaded by other youtube accounts

## [Information Theory, Inference and Learning Algorithms](http://www.inference.org.uk/mackay/itila/)
A provocative idea from this book is that's always at the back of my mind is _modeling and compression are exactly the same_. I also try to do statistics _axiomatically_ instead of memorizing conventions. If either of those are resonant to you, please join me in MacKay's bayesian dojo. 

## [Category Theory by Bartosz Milewski](https://www.youtube.com/user/DrBartosz/videos)

## [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/)
Whenever a tutorial or guide underjustifies it's assumptions or isn't as generalized as I want, I consult the jedi masters.

## [MIRI's Research Guide](https://intelligence.org/research-guide/)

# Doing good and the long term future
- [80000 hours](https://80000hours.org)
- [Good Food Institute](https://www.gfi.org/blog)
- [Superintelligence](https://www.goodreads.com/book/show/20527133-superintelligence)
